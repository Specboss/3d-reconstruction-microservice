# Meshroom Processing Microservice

Enterprise-grade 3D reconstruction microservice using Meshroom photogrammetry with RabbitMQ message queue and MinIO object storage.

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Main Backend   â”‚ (Your application)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP POST /api/v1/reconstruct
         â”‚ + image_urls
         â”‚ + callback_url
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Meshroom API    â”‚ (REST Gateway)
â”‚  (FastAPI)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Publish job
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RabbitMQ      â”‚ (Message Queue)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Consume
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Meshroom Worker â”‚ (Processing)
â”‚   Ã— N replicas  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ Upload results
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     Webhook
â”‚     MinIO       â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º  Main Backend
â”‚   (Storage)     â”‚              (Callback)
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- **Scalable**: Run multiple workers independently
- **Reliable**: RabbitMQ ensures jobs aren't lost
- **Async**: Non-blocking REST API with webhook callbacks
- **Secure**: API key authentication
- **Production-ready**: Docker Compose, health checks, logging

## ğŸš€ Quick Start

### 1. Prerequisites

- Docker & Docker Compose
- MinIO or S3-compatible storage
- Images uploaded to MinIO/S3

### 2. Setup

```bash
# Clone repository
cd meshroom-processing-microservice

# Copy environment variables
cp env.example .env

# Edit .env with your settings
nano .env
```

**Required environment variables:**

```env
# MinIO/S3 credentials
AWS_ACCESS_KEY_ID=minioadmin
AWS_SECRET_ACCESS_KEY=minioadmin

# RabbitMQ credentials
BROKER_USER=user
BROKER_PASSWORD=pass

# API security (CHANGE IN PRODUCTION!)
X_API_KEY=your-secret-api-key-change-in-production
```

### 3. Run

**Local development:**
```bash
docker compose -f local.yml up --build
```

**Production:**
```bash
docker compose -f production.yml up -d --build
```

### 4. Access Services

- **API**: http://localhost:8000
- **API Docs**: http://localhost:8000/docs
- **RabbitMQ Management**: http://localhost:15672 (user/pass)
- **MinIO Console**: http://localhost:9001 (minioadmin/minioadmin)

## ğŸ“¡ API Usage

### Create Reconstruction Job

```bash
curl -X POST http://localhost:8000/api/v1/reconstruct \
  -H "Content-Type: application/json" \
  -H "X-API-Key: your-secret-api-key-change-in-production" \
  -d '{
    "image_urls": [
      "http://minio:9000/3d-generator/photo1.jpg",
      "http://minio:9000/3d-generator/photo2.jpg"
    ],
    "callback_url": "https://your-backend.com/api/webhooks/meshroom",
    "metadata": {
      "user_id": 123,
      "project_id": 456
    }
  }'
```

**Response:**
```json
{
  "job_id": "abc123def456",
  "status": "queued",
  "message": "Job abc123def456 has been queued for processing"
}
```

### Webhook Callback

When job completes, your backend will receive:

```json
POST https://your-backend.com/api/webhooks/meshroom
{
  "job_id": "abc123def456",
  "status": "completed",
  "result_url": "http://minio:9000/3d-generator/results/abc123def456/texturedMesh.obj",
  "metadata": {
    "user_id": 123,
    "project_id": 456
  }
}
```

**On failure:**
```json
{
  "job_id": "abc123def456",
  "status": "failed",
  "error": "Meshroom process failed with exit code 1",
  "metadata": {...}
}
```

## ğŸ”§ Integration Example (Python)

```python
import httpx

async def create_3d_model(user_id: int, image_urls: list[str]):
    """Submit 3D reconstruction job."""
    
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://meshroom-api:8000/api/v1/reconstruct",
            json={
                "image_urls": image_urls,
                "callback_url": "https://your-backend.com/api/webhooks/meshroom",
                "metadata": {"user_id": user_id}
            },
            headers={"X-API-Key": "your-secret-api-key"},
            timeout=30.0,
        )
        result = response.json()
    
    return result["job_id"]

# Webhook handler in your backend
@app.post("/api/webhooks/meshroom")
async def meshroom_callback(payload: dict):
    job_id = payload["job_id"]
    status = payload["status"]
    
    if status == "completed":
        result_url = payload["result_url"]
        user_id = payload["metadata"]["user_id"]
        
        # Download and save model
        await save_user_model(user_id, result_url)
        await notify_user(user_id, "Your 3D model is ready!")
    
    return {"status": "ok"}
```

## ğŸ“ Project Structure

```
meshroom-processing-microservice/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # REST API Gateway
â”‚   â”œâ”€â”€ worker.py                  # Job consumer
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ dependencies.py        # FastAPI dependencies
â”‚   â”‚   â”œâ”€â”€ models.py              # Request/response models
â”‚   â”‚   â””â”€â”€ v1/routers/
â”‚   â”‚       â””â”€â”€ reconstruct.py     # Reconstruction endpoints
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ broker.py              # RabbitMQ client
â”‚   â”‚   â”œâ”€â”€ logger.py              # Loguru configuration
â”‚   â”‚   â”œâ”€â”€ settings.py            # Configuration models
â”‚   â”‚   â””â”€â”€ storage/
â”‚   â”‚       â”œâ”€â”€ base/storage.py    # Storage interface
â”‚   â”‚       â””â”€â”€ minio.py           # MinIO implementation
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â””â”€â”€ meshroom_service.py    # Meshroom processing logic
â”‚   â””â”€â”€ config/
â”‚       â””â”€â”€ app_config.json        # Application config
â”œâ”€â”€ pipelines/
â”‚   â””â”€â”€ default.mg                 # Meshroom pipeline
â”œâ”€â”€ local.yml                      # Docker Compose (dev)
â”œâ”€â”€ production.yml                 # Docker Compose (prod)
â”œâ”€â”€ Dockerfile                     # Container image
â””â”€â”€ requirements.txt               # Python dependencies
```

## ğŸ” Monitoring

### RabbitMQ Management UI

1. Open http://localhost:15672
2. Login with BROKER_USER/BROKER_PASSWORD
3. View queue depth, message rates, workers

### Logs

```bash
# API logs
docker logs meshroom-api -f

# Worker logs
docker logs meshroom-worker -f

# All services
docker compose -f local.yml logs -f
```

## âš™ï¸ Configuration

### `app/config/app_config.json`

```json
{
  "logging": {
    "level": "DEBUG"
  },
  "aws": {
    "endpoint_url": "http://minio:9000",
    "bucket_name": "3d-generator"
  },
  "broker": {
    "host": "rabbitmq",
    "port": 5672,
    "queue_name": "meshroom_jobs"
  },
  "meshroom": {
    "binary": "/opt/meshroom/meshroom_photogrammetry",
    "pipeline_path": "/service/pipelines/default.mg",
    "workspace_dir": "/var/lib/meshroom",
    "resources": {
      "max_concurrent_jobs": 1,
      "timeout_seconds": 7200
    }
  }
}
```

## ğŸš€ Scaling

### Horizontal Scaling (More Workers)

```bash
# Scale to 5 workers
docker compose -f production.yml up -d --scale worker=5
```

### Vertical Scaling (GPU Support)

Edit `production.yml`:

```yaml
worker:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: 1
            capabilities: [gpu]
```

## ğŸ”’ Security

1. **Change API Key**: Update `X_API_KEY` in `.env`
2. **Change RabbitMQ credentials**: Update `BROKER_USER`/`BROKER_PASSWORD`
3. **Use HTTPS**: Deploy behind reverse proxy (Nginx, Traefik)
4. **Network isolation**: Use Docker networks in production

## ğŸ› Troubleshooting

### Job stuck in queue

```bash
# Check worker logs
docker logs meshroom-worker-1 -f

# Check RabbitMQ
# Visit http://localhost:15672 â†’ Queues
```

### Out of memory

- Reduce `max_concurrent_jobs` in config
- Increase worker resources
- Scale horizontally instead

### Meshroom timeout

- Increase `timeout_seconds` in config
- Use fewer/smaller images
- Check GPU availability

## ğŸ“ Development

### Install dependencies locally

```bash
python -m venv venv
source venv/bin/activate  # or `venv\Scripts\activate` on Windows
pip install -r requirements.txt
```

### Run tests

```bash
pytest tests/
```

### Code quality

```bash
ruff check .
mypy app/
```

## ğŸ“„ License

MIT License - see LICENSE file

## ğŸ¤ Contributing

Pull requests welcome! Please ensure:

1. Code follows project structure
2. All tests pass
3. Documentation updated

---

**Made with â¤ï¸ for 3D reconstruction**

